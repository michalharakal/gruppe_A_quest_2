{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9adKsJhAfA1"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/t81_558_deep_learning/blob/master/manual_setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H7vr6-qOAfA2"
   },
   "source": [
    "GAN-Functions\n",
    "Created on Wed Nov 18 07:56:39 2020\n",
    "\n",
    "@author: Wolfgang Reuter\n",
    "\n",
    "Inspired and altered from:\n",
    "    https://github.com/platonovsimeon/dcgan-facegenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KwwRaZUNAfA2",
    "outputId": "cd92c34d-cc37-4639-ce96-ec09afa87ecb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.2.0\n",
      "Keras Version: 2.3.0-tf\n",
      "\n",
      "Python 3.7.9 (default, Aug 31 2020, 12:42:55) \n",
      "[GCC 7.3.0]\n",
      "Pandas 1.1.3\n",
      "Scikit-Learn 0.23.2\n",
      "WARNING:tensorflow:From <ipython-input-1-812fc96d3476>:15: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "# What version of Python do you have?\n",
    "import sys\n",
    "\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import tensorflow as tf\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frszmBXznxdU"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "KQkNVN5cnkpC"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-38cf6acf96ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Custom functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# in ipynb see functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgan_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Imports\n",
    "# =============================================================================\n",
    "\n",
    "# Model functions from keras\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Flatten, \\\n",
    "                         BatchNormalization, Activation, ZeroPadding2D\n",
    "\n",
    "\n",
    "#from tensorflow.keras.layers.advanced_activations import LeakyReLU  ---geht nicht\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "#from tensorflow.keras.layers.convolutional import UpSampling2D, Conv2D ---geht nicht\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# matplotlib will help with displaying the results\n",
    "import matplotlib.pyplot as plt\n",
    "# numpy for some mathematical operations\n",
    "import numpy as np\n",
    "# PIL for opening,resizing and saving images\n",
    "from PIL import Image\n",
    "# tqdm for a progress bar when loading the dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "#os library is needed for extracting filenames from the dataset folder.\n",
    "import os\n",
    "\n",
    "# Custom functions\n",
    "# in ipynb see functions\n",
    "import utils.gan_functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oQnRJ3Xn2ht"
   },
   "source": [
    "# Paths and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-XOgWrPIn45p"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Paths and Variables\n",
    "# =============================================================================\n",
    "\n",
    "# Data Parameters\n",
    "imgs_dir = 'data'\n",
    "\n",
    "image_height, image_width, channels = 64, 64, 3\n",
    "image_shape = (image_width, image_height, channels)\n",
    "\n",
    "random_noise_dimension = 100\n",
    "rows, columns = 4, 8\n",
    "\n",
    "save_images_interval = 100\n",
    "\n",
    "target_dir = 'generated_faces'\n",
    "\n",
    "target_fn = \"/generated\"\n",
    "\n",
    "# Model parameters\n",
    "\n",
    "use_pretrained_model = False\n",
    "\n",
    "pretrained_model_path_generator = \"saved_models/face_generator.h5\"\n",
    "pretrained_model_path_discriminator = \"saved_models/face_discriminator.h5\"\n",
    "\n",
    "epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "start_epoch = 0\n",
    "if use_pretrained_model:\n",
    "    assert(start_epoch == 0)\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# TODO: Rewrite get_random_noise() to use batch_size\n",
    "assert(rows * columns == batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_YXaX7_oG3a"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWX3d9KxoQ57"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Functions\n",
    "# =============================================================================\n",
    "\n",
    "# A compendium of available functions in gan_functions \n",
    "\n",
    "# get_random_noise(rows, columns, random_noise_dimensions)\n",
    "\n",
    "# build_generator(random_noise_dimension, channels)\n",
    "\n",
    "# build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# Functions (from gan_functions)\n",
    "# =============================================================================\n",
    "\n",
    "def get_random_noise(rows, columns, random_noise_dimension):\n",
    "    \"\"\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rows : Integer\n",
    "        Pixel size of the height of a \"noise image\"\n",
    "    columns : Integer\n",
    "        Pixel size of the width of an \"noise image\"\n",
    "    random_noise_dimension : Integer\n",
    "        Number of channels of a \"noise image\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    2-dim numpy array\n",
    "        Array of shape (rows * columns, random_noise_dimensions) with \n",
    "        normally distributed values with mean 0 and standard deviation 1\n",
    "\n",
    "    \"\"\"\n",
    "    return np.random.normal(0, 1, (rows * columns, random_noise_dimension))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(datafolder, image_width, image_height, channels):\n",
    "    \"\"\"\n",
    "    Loads the training data from a specified folder\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    datafolder : String\n",
    "        Path to directory where the training images are stored\n",
    "    image_width : Integer\n",
    "        Pixel width of the images (Nr. of columns)\n",
    "    image_height : Integer\n",
    "        Pixel height of the images (Nr. of rows)\n",
    "    channels : Integer\n",
    "        Number of color channels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    training_data : 4-dim numpy array\n",
    "        The training data as numpy array of shaape:    \n",
    "            (Nr. images, image_height, image_width, Nr. channels) \n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Loading training data...\")\n",
    "\n",
    "    training_data = []\n",
    "    #Finds all files in datafolder\n",
    "    filenames = os.listdir(datafolder)\n",
    "    for filename in tqdm(filenames):\n",
    "        #Combines folder name and file name.\n",
    "        path = os.path.join(datafolder,filename)\n",
    "        #Opens an image as an Image object.\n",
    "        image = Image.open(path)\n",
    "        #Resizes to a desired size.\n",
    "        image = image.resize((image_width,image_height),Image.ANTIALIAS)\n",
    "        #Creates an array of pixel values from the image.\n",
    "        pixel_array = np.asarray(image)\n",
    "        \n",
    "        # Clip alpha channel, if existant\n",
    "        if pixel_array.shape[2] > channels: \n",
    "            pixel_array = pixel_array[:,:,:channels]\n",
    "\n",
    "        training_data.append(pixel_array)\n",
    "\n",
    "    #training_data is converted to a numpy array\n",
    "    training_data = \\\n",
    "        np.reshape(training_data,(-1, image_width, image_height, channels))\n",
    "    return training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(random_noise_dimension, channels):\n",
    "    ''' \n",
    "    create generator-model\n",
    "    \n",
    "    Parameter:\n",
    "        random_noise_dimension : Number of channels of a \"noise image\" (Integer)\n",
    "        channels : Number of color channels (Integer)\n",
    "        \n",
    "    Output:\n",
    "        Generator-Model\n",
    "    '''\n",
    "    #Generator attempts to fool discriminator by generating new images.\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256*4*4,activation=\"relu\",\\\n",
    "                    input_dim=random_noise_dimension))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "    \n",
    "\n",
    "    # Four layers of upsampling, convolution, batch normalization \n",
    "    # and activation.\n",
    "    # 1. Upsampling: Input data is repeated. Default is (2,2). \n",
    "    #    In that case a 4x4x256 array becomes an 8x8x256 array.\n",
    "    # 2. Convolution: If you are not familiar, you should watch \n",
    "    #    this video: https://www.youtube.com/watch?v=FTr3n7uBIuE\n",
    "    # 3. Normalization normalizes outputs from convolution.\n",
    "    # 4. Relu activation:  f(x) = max(0,x). If x < 0, then f(x) = 0.\n",
    "\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "\n",
    "    # Last convolutional layer outputs as many featuremaps as channels \n",
    "    # in the final image.\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    # model.add(Conv2D(channels, kernel_size=1, padding=\"same\"))\n",
    "    # tanh maps everything to a range between -1 and 1.\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    # show the summary of the model architecture\n",
    "    model.summary()\n",
    "\n",
    "    # Placeholder for the random noise input\n",
    "    input = Input(shape=(random_noise_dimension,))\n",
    "    #Model output\n",
    "    generated_image = model(input)\n",
    "\n",
    "    # Change the model type from Sequential to Model (functional API) \n",
    "    # More at: https://keras.io/models/model/.\n",
    "    return Model(input,generated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape):\n",
    "    #Discriminator attempts to classify real and generated images\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, \\\n",
    "                     input_shape=image_shape, padding=\"same\"))\n",
    "    #Leaky relu is similar to usual relu. If x < 0 then f(x) = x * alpha, \n",
    "    # otherwise f(x) = x.\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Dropout blocks some connections randomly. This help the model \n",
    "    # to generalize better. 0.25 means that every connection has a 25% \n",
    "    # chance of being blocked.\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    # Zero padding adds additional rows and columns to the image. \n",
    "    # Those rows and columns are made of zeros.\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    # Flatten layer flattens the output of the previous layer to a single \n",
    "    # dimension.\n",
    "    model.add(Flatten())\n",
    "    # Outputs a value between 0 and 1 that predicts whether image is \n",
    "    # real or generated. 0 = generated, 1 = real.\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    input_image = Input(image_shape)\n",
    "\n",
    "    #Model output given an image.\n",
    "    validity = model(input_image)\n",
    "\n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(epoch, random_noise_dimension, generator, target_dir, \n",
    "                target_fn, start_epoch = 0):\n",
    "    #Save generated images for demonstration purposes using matplotlib.pyplot.\n",
    "    rows, columns = 5, 5\n",
    "    noise = np.random.normal(0, 1, (rows * columns, random_noise_dimension))\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "    figure, axis = plt.subplots(rows, columns)\n",
    "    image_count = 0\n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            axis[row,column].imshow(generated_images[image_count, :], \\\n",
    "                                    cmap='spring')\n",
    "            axis[row,column].axis('off')\n",
    "            image_count += 1\n",
    "    figure.savefig(target_dir + target_fn + \"_%d.png\" % (start_epoch + epoch))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-gQhMxyoT1-"
   },
   "source": [
    "# Get the training data and normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vLVp31BIoWrV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-5d7dfcafde99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                   \u001b[0mimage_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                   \u001b[0mimage_height\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                   channels)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#Map all values to a range between -1 and 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8b7bd2564aed>\u001b[0m in \u001b[0;36mget_training_data\u001b[0;34m(datafolder, image_width, image_height, channels)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtraining_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#Finds all files in datafolder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mfilenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatafolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#Combines folder name and file name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Get the training data and normalize it\n",
    "# =============================================================================\n",
    "\n",
    "#Get the real images\n",
    "'''training_data = gan_functions.get_training_data(imgs_dir, \n",
    "                                                image_width,\n",
    "                                                image_height, \n",
    "                                                channels)\n",
    "only py\n",
    "'''\n",
    "\n",
    "\n",
    "'''I HAT IT---- where is the data, which path\n",
    "I can first see that something works before I change ...  '''\n",
    "training_data = get_training_data(imgs_dir,\n",
    "                                  image_width,\n",
    "                                  image_height,\n",
    "                                  channels)\n",
    " \n",
    "#Map all values to a range between -1 and 1.\n",
    "training_data = training_data / 127.5 - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mLFR9KMoaa8"
   },
   "source": [
    "# Set up the labels for generated and real images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p_3lN4DooJf"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Set up the labels for generated and real images\n",
    "# =============================================================================\n",
    "\n",
    "# Two arrays of labels. Labels for real images: [1,1,1 ... 1,1,1], \n",
    "# labels for generated images: [0,0,0 ... 0,0,0]\n",
    "labels_for_real_images = np.ones((batch_size,1)) - 0.15\n",
    "labels_for_generated_images = np.zeros((batch_size,1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZGVmkQeose3"
   },
   "source": [
    "# Set up generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FSnklRG3owQp"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Set up generator and discriminator\n",
    "# =============================================================================\n",
    "\n",
    "if use_pretrained_model:\n",
    "    generator = load_model(pretrained_model_path_generator)\n",
    "    discriminator = load_model(pretrained_model_path_discriminator)\n",
    "else:\n",
    "    generator = gan_functions.build_generator(random_noise_dimension, channels)\n",
    "    discriminator = gan_functions.build_discriminator(image_shape)\n",
    "    \n",
    "discriminator.compile(loss=\"binary_crossentropy\", \n",
    "                      optimizer=optimizer,\n",
    "                      metrics=[\"accuracy\"])\n",
    "\n",
    "# Set up the actual GAN (= combined_model)\n",
    "random_input = Input(shape=(random_noise_dimension,))\n",
    "generated_image = generator(random_input)\n",
    "discriminator.trainable = False\n",
    "validity = discriminator(generated_image)#\n",
    "combined_model = Model(random_input, validity) # This is the actual GAN\n",
    "\n",
    "combined_model.compile(loss=\"binary_crossentropy\",\n",
    "                       optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgTqps46nbbU"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Train GAN\n",
    "# =============================================================================\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Select a random batch of real images\n",
    "    indices = np.random.randint(0,training_data.shape[0],batch_size)\n",
    "    real_images = training_data[indices]\n",
    "    \n",
    "    # Generate random noise for a whole batch.\n",
    "    random_noise = gan_functions.get_random_noise(rows, \n",
    "                                                  columns, \n",
    "                                                  random_noise_dimension)\n",
    "    \n",
    "    discriminator.trainable = True\n",
    "    \n",
    "    #Generate a batch of new images.\n",
    "    generated_images = generator.predict(random_noise)\n",
    "    \n",
    "    #Train the discriminator on real images.\n",
    "    discriminator_loss_real = \\\n",
    "        discriminator.train_on_batch(real_images,\n",
    "                                     labels_for_real_images)\n",
    "    #Train the discriminator on generated images.\n",
    "    discriminator_loss_generated = \\\n",
    "        discriminator.train_on_batch(generated_images,\n",
    "                                     labels_for_generated_images)\n",
    "    #Calculate the average discriminator loss.\n",
    "    discriminator_loss = 0.5 * np.add(discriminator_loss_real,\n",
    "                                      discriminator_loss_generated)\n",
    "    \n",
    "    # Train the generator using the combined model. Generator tries to trick \n",
    "    # discriminator into mistaking generated images as real.\n",
    "    discriminator.trainable = False\n",
    "    \n",
    "    labels_for_tricking_discriminator = np.ones((batch_size,1))\n",
    "    generator_loss = \\\n",
    "        combined_model.train_on_batch(random_noise,labels_for_tricking_discriminator)\n",
    "    \n",
    "    # Training ends above (one iteration) \n",
    "    # This is only for display and saving models\n",
    "    print (\"%d [Discriminator loss: %f, acc.: %.2f%%] [Generator loss: %f]\" % \\\n",
    "           (epoch, discriminator_loss[0], 100*discriminator_loss[1], \n",
    "            generator_loss))\n",
    "\n",
    "    if epoch % save_images_interval == 0:\n",
    "        gan_functions.save_images(epoch, random_noise_dimension, generator, \n",
    "                                  target_dir, target_fn, start_epoch)\n",
    "        \n",
    "    #Save the model for a later use\n",
    "    generator.save(pretrained_model_path_generator)\n",
    "    discriminator.save(pretrained_model_path_discriminator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kEs9VZ0enb7n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "name": "Face_GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8 tf_test38",
   "language": "python",
   "name": "tf_test38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
